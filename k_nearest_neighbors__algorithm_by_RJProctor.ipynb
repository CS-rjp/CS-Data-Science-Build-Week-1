{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "k_nearest_neighbors__algorithm_by_RJProctor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amended-sharing"
      },
      "source": [
        "# K-Nearest Neighbors Classification Algorithim:  Python Class Implementation\n"
      ],
      "id": "amended-sharing"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "banned-colon"
      },
      "source": [
        "# import libraries\n",
        "import requests\n",
        "from contextlib import closing\n",
        "import csv\n",
        "import pandas as pd\n",
        "from random import seed\n",
        "from scipy.spatial.distance import pdist\n",
        "import numpy as np\n",
        "from random import randrange\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ],
      "id": "banned-colon",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "worse-thong",
        "outputId": "22d4d37b-c107-4a5b-c6eb-5212494ac1f9"
      },
      "source": [
        "file_name = \"IRIS.csv\"\n",
        "cols = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
        "dataframe = pd.read_csv(file_name, names=cols, skiprows=1)\n",
        "dataset = pd.read_csv(file_name, names=cols, skiprows=1).drop('class', axis=1)\n",
        "print(dataframe.head())\n",
        "print(dataset.head())\n"
      ],
      "id": "worse-thong",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width        class\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
            "   sepal_length  sepal_width  petal_length  petal_width\n",
            "0           5.1          3.5           1.4          0.2\n",
            "1           4.9          3.0           1.4          0.2\n",
            "2           4.7          3.2           1.3          0.2\n",
            "3           4.6          3.1           1.5          0.2\n",
            "4           5.0          3.6           1.4          0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6psa437zuCJ"
      },
      "source": [
        "X = dataset\n",
        "y = dataframe[\"class\"]"
      ],
      "id": "d6psa437zuCJ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "accepted-memory",
        "outputId": "000eec67-73ab-4422-e3c7-624240998848"
      },
      "source": [
        "dataframe.describe()\n"
      ],
      "id": "accepted-memory",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.054000</td>\n",
              "      <td>3.758667</td>\n",
              "      <td>1.198667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.433594</td>\n",
              "      <td>1.764420</td>\n",
              "      <td>0.763161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sepal_length  sepal_width  petal_length  petal_width\n",
              "count    150.000000   150.000000    150.000000   150.000000\n",
              "mean       5.843333     3.054000      3.758667     1.198667\n",
              "std        0.828066     0.433594      1.764420     0.763161\n",
              "min        4.300000     2.000000      1.000000     0.100000\n",
              "25%        5.100000     2.800000      1.600000     0.300000\n",
              "50%        5.800000     3.000000      4.350000     1.300000\n",
              "75%        6.400000     3.300000      5.100000     1.800000\n",
              "max        7.900000     4.400000      6.900000     2.500000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "competitive-controversy",
        "outputId": "295e8c0e-3a87-486b-9cce-35ec831f99d1"
      },
      "source": [
        "dataframe.info()"
      ],
      "id": "competitive-controversy",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  150 non-null    float64\n",
            " 1   sepal_width   150 non-null    float64\n",
            " 2   petal_length  150 non-null    float64\n",
            " 3   petal_width   150 non-null    float64\n",
            " 4   class         150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "legitimate-investigation",
        "outputId": "eab64e7f-f7af-45ca-fa7a-34f2c51d229e"
      },
      "source": [
        "dataframe['class'].unique()"
      ],
      "id": "legitimate-investigation",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "removable-devil",
        "outputId": "2d2dda65-e426-4d72-ab7a-02ae896024c7"
      },
      "source": [
        "class KNN:\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.random_state = 42\n",
        "        self.dataframe = dataframe  # technical debt \n",
        "        self.X = dataset\n",
        "        self.y = dataframe['class']\n",
        "        self.minmax = []\n",
        "        self.class_val_labels = []\n",
        "        self.class_uniques = []\n",
        "        self.X_train = []\n",
        "        self.X_test = []\n",
        "        self.distance = 0.0\n",
        "        self.n_neighbors = 3\n",
        "\n",
        "\n",
        "    col_class = y\n",
        "\n",
        "    # Data Wrangling\n",
        "    def string_to_float(self, X):\n",
        "        \"\"\"\n",
        "        convert string column values to floats;\n",
        "        not needed -> values are floats   \n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def ints_to_floats(self, X):\n",
        "        \"\"\"\n",
        "        convert integers values to floats;\n",
        "        not needed -> values are floats  \n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    \n",
        "    def create_unique_class_id(self, dataframe):\n",
        "        \"\"\"\n",
        "        identify unique classification values; \n",
        "        encode column values as integer labels while \n",
        "        keeping human readable format too\n",
        "        \"\"\"\n",
        "        unique = ('Iris-setosa', 'Iris-versicolor', 'Iris-virginica')\n",
        "        cat = pd.Categorical(['1', '2', '3'], categories=[unique])\n",
        "        self.class_val_labels, self.class_uniques = pd.factorize(cat)\n",
        "\n",
        "   \n",
        "    # Pre-Processing\n",
        "    def train_test_split(self, X):\n",
        "       \n",
        "        X_train_sz = 0.33 * len(self.X)\n",
        "        copy_X = list(self.X)\n",
        "        while len(self.X_train) < X_train_sz:\n",
        "          # determine index values of dataset within random range\n",
        "          index = randrange(len(copy_X))\n",
        "          # at an index value of the duplicate dataset list, \n",
        "          # move the value to the end of the X_train list\n",
        "          self.X_train.append(copy_X.pop(index))\n",
        "        # remainder of split assigned to X_test\n",
        "        self.X_test = copy_X\n",
        "\n",
        "\n",
        "    def min_max(self):\n",
        "        \"\"\"\n",
        "        find the minimum and maximum values for each column;\n",
        "        create a list of these values\n",
        "        \"\"\"       \n",
        "        for row in self.X_train:            \n",
        "            # for each row in the dataset, find the minimum value\n",
        "            minimum = min(row) # row[i].min(self.X_train)   \n",
        "            # for each row in the dataset, find the maximum value\n",
        "            maximum = min(row) # row[i].max(self.X_train)  \n",
        "\n",
        "            # add both minimum and maximum values to \n",
        "            # the end of the minmax list \n",
        "            self.minmax.append([minimum, maximum])  \n",
        "\n",
        "\n",
        "    def normalize(self):\n",
        "        \"\"\"\n",
        "        rescale dataset columns to range 0-1;\n",
        "        must be called after train/test split to avoid leakage/bias;\n",
        "        returns ndarry of shape(n_samples, n_features) transformed data\n",
        "        \"\"\"\n",
        "        for row in self.X_train:\n",
        "          for i in range(len(row)):\n",
        "            row[i] = (row[i] - self.minmax[i][0]) / (self.minmax[i][1] - self.minmax[i][0])     \n",
        "    \n",
        "\n",
        "    def calculate_ed(self, row1, row2):\n",
        "        \"\"\"\n",
        "        calculate euclidean distance between vectors\n",
        "        \"\"\"\n",
        "        # convert to numpy arrays (just in case)\n",
        "        row1, row2 = np.array(row1), np.array(row2)\n",
        "\n",
        "        # iterate over each dimension of the vectors\n",
        "        for i in range(len(row1) - 1):\n",
        "            # increment distance\n",
        "            self.distance += (row1[i] - row2[i]) **2\n",
        "\n",
        "        # return the square root\n",
        "        return np.sqrt(self.distance)\n",
        "\n",
        "\n",
        "    # def cross_val_split(self):\n",
        "    #     \"\"\"\n",
        "    #     split dataset into k folds\n",
        "    #     \"\"\"\n",
        "    #     # create empty list for split dataset and copy dataset to list\n",
        "    #     self.split_X_test = []\n",
        "    #     self.copy_X_test = list(self.X_test)\n",
        "\n",
        "    #     # determine fold size\n",
        "    #     fold_sz = int(len(self.X_test) / self.k_folds)\n",
        "\n",
        "    #     for _ in range(self.k_folds):\n",
        "    #       # create empty empty list to hold folds\n",
        "    #       self.fold = []\n",
        "    #       while len(self.folds) < fold:\n",
        "    #         # determine index values of dataset within random range\n",
        "    #         idx = randrange(len(copy_X_test))\n",
        "    #         # at an index value of the duplicate dataset list, \n",
        "    #         # move the value to the end of the fold list\n",
        "    #         self.fold.append(copy_X_test.pop(idx))\n",
        "    #       # append the split_dataset with the fold list\n",
        "    #       self.split_X_test.append(self.fold)\n",
        "    #     self.X_test_folded = self.split_X_test\n",
        "\n",
        "    \n",
        "    # Implement K-NN Algorithm\n",
        "    def get_neighbors(self, X_train, test_row, num_neighbors):\n",
        "        \"\"\"\n",
        "        locate most similar neighbors\n",
        "        \"\"\"\n",
        "        dist = []\n",
        "\n",
        "        ## TODO...complete in full OOP\n",
        "        \n",
        "    \n",
        "\n",
        "    def predict_class(self):\n",
        "        \"\"\"\n",
        "        make a prediction with neighbors\n",
        "        \"\"\"\n",
        "        pass\n",
        "        ## TODO...complete in full OOP\n",
        "\n",
        "\n",
        "    def k_nn(self):\n",
        "        \"\"\"\n",
        "        K-NN algorithm\n",
        "        \"\"\"\n",
        "        pass\n",
        "        ## TODO...complete in full OOP\n",
        "\n",
        "    \n",
        "    # Evaluate K-NN Algorithm\n",
        "    def accuracy_metrics(self):\n",
        "        \"\"\"\n",
        "        calculate accuracy (prediction error) percentage;\n",
        "        the set of labels predicted for a sample must \n",
        "        exactly match the corresponding set of labels \n",
        "        in y_true\n",
        "        \"\"\"\n",
        "        correct = 0\n",
        "        for i in range(len(actual)):\n",
        "          if actual[i] == predicted[i]:\n",
        "            correct +=1\n",
        "            return correct / float(len(actual)) * 100\n",
        "\n",
        "        ## TODO...refactor from psuedo to OOP\n",
        "\n",
        "\n",
        "    # def cross_val_metric(self):\n",
        "    #     \"\"\"\n",
        "    #     evaluate algorithm (model rules) using cross validation; \n",
        "    #     validated on the remaining part of the data \n",
        "    #     (i.e., test set) to compute a performance measure such \n",
        "    #     as accuracy\n",
        "    #     \"\"\"\n",
        "    #     folds = cross_val_split(X_test, k_folds)\n",
        "    #     self.scores = []\n",
        "\n",
        "    #     # TODO...refactor in OOP\n",
        "\n",
        "    #     for f in folds:\n",
        "    #       train_set = list(folds)\n",
        "    #       train_set.remove(f)\n",
        "    #       train_set = sum(train_set, [])\n",
        "\n",
        "    #       test_set = []\n",
        "    #       for row in fold:\n",
        "    #         copy_row = list(row)\n",
        "    #         test_set.append(copy_row)\n",
        "    #         # assumes the last value is output\n",
        "    #         row_copy[-1] = None\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # X = dataset\n",
        "    # y = dataframe[\"class\"]\n",
        "\n",
        "    # Test KNN class initializtion\n",
        "    knn = KNN(X, y)\n",
        "    print(X.head())\n",
        "    print(X.tail())\n",
        "    X.info()\n",
        "    print(y.head())\n",
        "\n",
        "    # test create_unigue_class_id method\n",
        "    knn.create_unique_class_id(dataframe)\n",
        "    print(knn.class_val_labels)\n",
        "\n",
        "    # test train_test_split method\n",
        "    knn.train_test_split(X)\n",
        "    print(knn.X_test.head())\n",
        "\n",
        "    # test min_max method\n",
        "    knn.min_max(X_train)\n",
        "    print(knn.minmax)\n",
        "\n",
        "    # test nortmalize method\n",
        "    # knn.normalize(X, minmax)\n",
        "    # print()\n",
        "\n",
        "    # test get_neighbors method\n",
        "\n",
        "    # test predict_class method\n",
        "\n",
        "    # test k_nn method\n",
        "\n",
        "    # test accuracy_metrics method\n",
        "\n",
        "     "
      ],
      "id": "removable-devil",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width\n",
            "0           5.1          3.5           1.4          0.2\n",
            "1           4.9          3.0           1.4          0.2\n",
            "2           4.7          3.2           1.3          0.2\n",
            "3           4.6          3.1           1.5          0.2\n",
            "4           5.0          3.6           1.4          0.2\n",
            "     sepal_length  sepal_width  petal_length  petal_width\n",
            "145           6.7          3.0           5.2          2.3\n",
            "146           6.3          2.5           5.0          1.9\n",
            "147           6.5          3.0           5.2          2.0\n",
            "148           6.2          3.4           5.4          2.3\n",
            "149           5.9          3.0           5.1          1.8\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 4 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  150 non-null    float64\n",
            " 1   sepal_width   150 non-null    float64\n",
            " 2   petal_length  150 non-null    float64\n",
            " 3   petal_width   150 non-null    float64\n",
            "dtypes: float64(4)\n",
            "memory usage: 4.8 KB\n",
            "0    Iris-setosa\n",
            "1    Iris-setosa\n",
            "2    Iris-setosa\n",
            "3    Iris-setosa\n",
            "4    Iris-setosa\n",
            "Name: class, dtype: object\n",
            "[-1 -1 -1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-51fbf9d0a99c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;31m# test train_test_split method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-51fbf9d0a99c>\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mX_train_sz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m           \u001b[0;31m# determine index values of dataset within random range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m           \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m           \u001b[0;31m# at an index value of the duplicate dataset list,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;31m# move the value to the end of the X_train list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/random.py\u001b[0m in \u001b[0;36mrandrange\u001b[0;34m(self, start, stop, step, _int)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mistart\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mistart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"empty range for randrange()\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# stop argument supplied.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: empty range for randrange()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIdSPWXikZzt"
      },
      "source": [
        "# K-Nearest Neighbors Classification Algorithim:  SciKit-Learn Model Implementation"
      ],
      "id": "fIdSPWXikZzt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6rPei4BkTMi"
      },
      "source": [
        "# import packages\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n"
      ],
      "id": "v6rPei4BkTMi",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1cF9bRVobJD"
      },
      "source": [
        "n_neighbors = 3\n",
        "random_state = 42\n",
        "\n",
        "# load dataset\n",
        "X = dataset\n",
        "y = dataframe[\"class\"]"
      ],
      "id": "N1cF9bRVobJD",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF2b9kfZpR4T"
      },
      "source": [
        "# split into train/test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.67, random_state=42, stratify = y)"
      ],
      "id": "xF2b9kfZpR4T",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQH7s4zLpwIU"
      },
      "source": [
        "# print(X_train)\n",
        "# print(X_test)\n",
        "# print(y_train)\n",
        "# print(y_test)"
      ],
      "id": "EQH7s4zLpwIU",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90yf-Pqald1C"
      },
      "source": [
        "# reduce dimensions to 2 with neighborhood component analysis\n",
        "nca = make_pipeline(\n",
        "    MinMaxScaler(),\n",
        "    NeighborhoodComponentsAnalysis(n_components=2, \n",
        "                           random_state=random_state)\n",
        "    )\n"
      ],
      "id": "90yf-Pqald1C",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy0okp0NrIpz"
      },
      "source": [
        "# use nearest neighbor classifier to evaluate  the methoda\n",
        "knn =  KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "\n",
        "# fit the method's model\n",
        "nca.fit(X_train, y_train)\n",
        "\n",
        "# fit nearest neighbor classifier on training set\n",
        "knn.fit(nca.transform(X_train), y_train)\n",
        "\n",
        "# calculate the nearest neighbor accuracy on the test set\n",
        "knn_accuracy_sklearn = knn.score(nca.transform(X_test), y_test)\n",
        "\n",
        "# calculate the nearest neighbor cross validation score on test set\n",
        "scores = cross_val_score(knn, X_train, y_train, cv=5)\n"
      ],
      "id": "cy0okp0NrIpz",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7USebJsdw0s6",
        "outputId": "31ce4d74-6955-4122-c8a5-3204b586068f"
      },
      "source": [
        "print(f'Accuracy Score: {knn_accuracy_sklearn}')\n",
        "print(f'Cross-validation Score: {np.mean(scores)}')\n",
        "# 0.967 is a good score for this dataset"
      ],
      "id": "7USebJsdw0s6",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.9702970297029703\n",
            "Cross-validation Score: 0.9800000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}