{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "k_nearest_neighbors__algorithm_by_RJProctor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amended-sharing"
      },
      "source": [
        "# K-Nearest Neighbors Classification Algorithim:  Python Class Implementation\n"
      ],
      "id": "amended-sharing"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "banned-colon"
      },
      "source": [
        "# import libraries\n",
        "import requests\n",
        "from contextlib import closing\n",
        "import csv\n",
        "import pandas as pd\n",
        "from random import seed\n",
        "from scipy.spatial.distance import pdist\n",
        "import numpy as np\n",
        "from random import randrange\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n"
      ],
      "id": "banned-colon",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "worse-thong",
        "outputId": "c8e3b40a-4a16-4006-eec0-b9e91a2f8de7"
      },
      "source": [
        "file_name = \"IRIS.csv\"\n",
        "cols = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
        "dataframe = pd.read_csv(file_name, names=cols, skiprows=1)\n",
        "dataset = pd.read_csv(file_name, names=cols, skiprows=1).drop('class', axis=1)\n",
        "print(dataframe.head())\n",
        "print(dataset.head())\n"
      ],
      "id": "worse-thong",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width        class\n",
            "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
            "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
            "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
            "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
            "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
            "   sepal_length  sepal_width  petal_length  petal_width\n",
            "0           5.1          3.5           1.4          0.2\n",
            "1           4.9          3.0           1.4          0.2\n",
            "2           4.7          3.2           1.3          0.2\n",
            "3           4.6          3.1           1.5          0.2\n",
            "4           5.0          3.6           1.4          0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6psa437zuCJ"
      },
      "source": [
        "X = dataset\n",
        "y = dataframe[\"class\"]"
      ],
      "id": "d6psa437zuCJ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "accepted-memory",
        "outputId": "9a2b60b3-3056-4ed3-b135-638f00e3c754"
      },
      "source": [
        "dataframe.describe()\n"
      ],
      "id": "accepted-memory",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal_length</th>\n",
              "      <th>sepal_width</th>\n",
              "      <th>petal_length</th>\n",
              "      <th>petal_width</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "      <td>150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.843333</td>\n",
              "      <td>3.054000</td>\n",
              "      <td>3.758667</td>\n",
              "      <td>1.198667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.828066</td>\n",
              "      <td>0.433594</td>\n",
              "      <td>1.764420</td>\n",
              "      <td>0.763161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.300000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.100000</td>\n",
              "      <td>2.800000</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.350000</td>\n",
              "      <td>1.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>5.100000</td>\n",
              "      <td>1.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>4.400000</td>\n",
              "      <td>6.900000</td>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sepal_length  sepal_width  petal_length  petal_width\n",
              "count    150.000000   150.000000    150.000000   150.000000\n",
              "mean       5.843333     3.054000      3.758667     1.198667\n",
              "std        0.828066     0.433594      1.764420     0.763161\n",
              "min        4.300000     2.000000      1.000000     0.100000\n",
              "25%        5.100000     2.800000      1.600000     0.300000\n",
              "50%        5.800000     3.000000      4.350000     1.300000\n",
              "75%        6.400000     3.300000      5.100000     1.800000\n",
              "max        7.900000     4.400000      6.900000     2.500000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "competitive-controversy",
        "outputId": "5f640a7f-6952-4ac3-f910-11169bf8fc27"
      },
      "source": [
        "dataframe.info()"
      ],
      "id": "competitive-controversy",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 150 entries, 0 to 149\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   sepal_length  150 non-null    float64\n",
            " 1   sepal_width   150 non-null    float64\n",
            " 2   petal_length  150 non-null    float64\n",
            " 3   petal_width   150 non-null    float64\n",
            " 4   class         150 non-null    object \n",
            "dtypes: float64(4), object(1)\n",
            "memory usage: 6.0+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "legitimate-investigation",
        "outputId": "b7746870-42e5-4898-88d2-0c58c4b85033"
      },
      "source": [
        "dataframe['class'].unique()"
      ],
      "id": "legitimate-investigation",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "removable-devil"
      },
      "source": [
        "# class KNN:\n",
        "\n",
        "#     def __init__(self, X, y):\n",
        "#         self.random_state = 42\n",
        "#         self.dataframe = dataframe  # technical debt \n",
        "#         self.X = dataset          # technical debt \n",
        "#         self.y = dataframe['class']   # technical debt \n",
        "#         self.minmax = []\n",
        "#         self.class_val_labels = []\n",
        "#         self.class_uniques = []\n",
        "#         self.X_train = pd.DataFrame()\n",
        "#         self.X_test = pd.DataFrame()\n",
        "#         self.distance = 0.0\n",
        "#         self.row1 = []\n",
        "#         self.row2 = []\n",
        "#         self.dist = []\n",
        "#         self.n_neighbors = 3\n",
        "#         self.neighbors = []\n",
        "#         self.pred_neigh = []\n",
        "#         self.pred_class = []\n",
        "#         self.correct = 0\n",
        "        \n",
        "   \n",
        "#     col_class = y\n",
        "\n",
        "#     # Data Wrangling\n",
        "#     def string_to_float(self, X):\n",
        "#         \"\"\"\n",
        "#         convert string column values to floats;\n",
        "#         not needed -> values are floats   \n",
        "#         \"\"\"\n",
        "#         pass\n",
        "\n",
        "\n",
        "#     def ints_to_floats(self, X):\n",
        "#         \"\"\"\n",
        "#         convert integers values to floats;\n",
        "#         not needed -> values are floats  \n",
        "#         \"\"\"\n",
        "#         pass\n",
        "    \n",
        "    \n",
        "#     def create_unique_class_id(self, dataframe):\n",
        "#         \"\"\"\n",
        "#         identify unique classification values; \n",
        "#         encode column values as integer labels while \n",
        "#         keeping human readable format too\n",
        "#         \"\"\"\n",
        "#         unique = ('Iris-setosa', 'Iris-versicolor', 'Iris-virginica')\n",
        "#         cat = pd.Categorical(['1', '2', '3'], categories=[unique])\n",
        "#         self.class_val_labels, self.class_uniques = pd.factorize(cat)\n",
        "\n",
        "   \n",
        "#     # Pre-Processing\n",
        "#     def train_test_split(self, X):\n",
        "       \n",
        "#         X_train_sz = 0.33 * len(self.X)\n",
        "#         copy_X = self.X.copy()\n",
        "#         while len(self.X_train) < X_train_sz:\n",
        "#           for row in copy_X:\n",
        "#             entries = []\n",
        "#             for idx in range(len(row)):\n",
        "#               # determine values of dataset within random range\n",
        "#               idx = randrange(len(copy_X))\n",
        "#               # find the value of the duplicate dataset, \n",
        "#               # move the value to the end of the X_train list\n",
        "#               entry = copy_X.loc[copy_X.iloc[idx] == item]\n",
        "#         found = pd.concat([entries])\n",
        "#         self.X_train = pd.concat(self.X_train, found)\n",
        "#               #self.X_train.iloc[idx].append(copy_X.iloc[idx])\n",
        "#         # remainder of split assigned to X_test\n",
        "#         self.X_test = pd.concat([self.X_train, copy_X]).drop_duplicates(keep=False)\n",
        "\n",
        "#     def min_max(self, X_train):\n",
        "#         \"\"\"\n",
        "#         find the minimum and maximum values for each column;\n",
        "#         create a list of these values\n",
        "#         \"\"\"     \n",
        "#         copy_X_train = self.X_train.copy()  \n",
        "#         for row in copy_X_train: \n",
        "#           for idx in range(len(row)): \n",
        "#             # determine values of dataset within random range\n",
        "#             idx = randrange(len(copy_X_train))\n",
        "#             # for each row in the dataset, find the minimum value\n",
        "#             minimum = min(copy_X_train.iloc[idx])    \n",
        "#             # for each row in the dataset, find the maximum value\n",
        "#             maximum = max(copy_X_train.iloc[idx]) \n",
        "\n",
        "#             # add both minimum and maximum values to \n",
        "#             # the end of the minmax list \n",
        "#             self.minmax.append([minimum, maximum])  \n",
        "\n",
        "\n",
        "#     def normalize(self, X_train, minmax):\n",
        "#         \"\"\"\n",
        "#         rescale dataset columns to range 0-1;\n",
        "#         must be called after train/test split to avoid leakage/bias;\n",
        "#         returns ndarry of shape(n_samples, n_features) transformed data\n",
        "#         \"\"\"\n",
        "#         for row in self.X_train:\n",
        "#           for i in range(len(row)):\n",
        "#             # filter edge cases that would result in errors\n",
        "#             if (self.minmax[i][1] - self.minmax[i][0])  != 0:\n",
        "#               row[i] = (row[i] - self.minmax[i][0]) / (self.minmax[i][1] - self.minmax[i][0])     \n",
        "#             else:\n",
        "#               # remove a pandas series item to drop edge cases from dataset\n",
        "#               self.X_train.drop(row[i])\n",
        "#               # self.y_train.drop(row[i])\n",
        "\n",
        "\n",
        "#     def calculate_ed(self, row1, row2):\n",
        "#         \"\"\"\n",
        "#         calculate euclidean distance between vectors\n",
        "#         \"\"\"\n",
        "#         # set up numpy arrays\n",
        "#         r1, r2 = np.arange(len(self.row1)), np.arange(len(self.row1))\n",
        "#         self.row1.append(r1)\n",
        "#         self.row2.append(r2)\n",
        "\n",
        "#         print(knn.X_train[1])\n",
        "#         print(self.X_train[1])\n",
        "      \n",
        "#         # iterate over each row in the training list\n",
        "#         for self.row1 in self.X_train:\n",
        "#           for i in range(len(self.row1)):\n",
        "#             #  convert to numpy arrays\n",
        "#             # r1a, r2a = np.arange(self.X_train[i]), np.arange(self.X_train[i])\n",
        "#             r1a = np.arange(self.X_train[i])\n",
        "#             # add each row in list as a vector in the numpy array\n",
        "#             self.row1.append(r1a)\n",
        "\n",
        "#         # iterate over each row in the training list\n",
        "#         for self.row2 in X_train:\n",
        "#           for i in range(len(self.row1)):\n",
        "#             #  convert to numpy arrays\n",
        "#             r2a = np.arange(self.X_train[i])\n",
        "#             # add each row in list as a vector in the numpy array\n",
        "#             self.row2.append(r2a) \n",
        "\n",
        "#         # iterate over each dimension of the vectors\n",
        "#         for i in range(len(self.row1)):\n",
        "#             # increment distance\n",
        "#             self.distance += (self.row1[i] - self.row2[i]) **2\n",
        "\n",
        "#         # return the square root\n",
        "#         return np.sqrt(self.distance)\n",
        "\n",
        "\n",
        "#     # def cross_val_split(self):\n",
        "#     #     \"\"\"\n",
        "#     #     split dataset into k folds\n",
        "#     #     \"\"\"\n",
        "#     #     # create empty list for split dataset and copy dataset to list\n",
        "#     #     self.split_X_test = []\n",
        "#     #     self.copy_X_test = list(self.X_test)\n",
        "\n",
        "#     #     # determine fold size\n",
        "#     #     fold_sz = int(len(self.X_test) / self.k_folds)\n",
        "\n",
        "#     #     for _ in range(self.k_folds):\n",
        "#     #       # create empty empty list to hold folds\n",
        "#     #       self.fold = []\n",
        "#     #       while len(self.folds) < fold:\n",
        "#     #         # determine index values of dataset within random range\n",
        "#     #         idx = randrange(len(copy_X_test))\n",
        "#     #         # at an index value of the duplicate dataset list, \n",
        "#     #         # move the value to the end of the fold list\n",
        "#     #         self.fold.append(copy_X_test.pop(idx))\n",
        "#     #       # append the split_dataset with the fold list\n",
        "#     #       self.split_X_test.append(self.fold)\n",
        "#     #     self.X_test_folded = self.split_X_test\n",
        "\n",
        "    \n",
        "#     # Implement K-NN Algorithm\n",
        "#     def get_neighbors(self, X_train, test_row, num_neighbors):\n",
        "#         \"\"\"\n",
        "#         locate most similar neighbors\n",
        "#         \"\"\"\n",
        "#         for train_row in X_train:\n",
        "#           d = knn.calculate_ed(test_row, train_row)\n",
        "#           self.dist.append((train_row, d))\n",
        "#           self.dist.sort(key=lambda tup: tup[1])\n",
        "\n",
        "#         for i in range(num_neighbors):\n",
        "#           self.neighbors.append(dist[i][0])\n",
        "          \n",
        "\n",
        "#     def predict_neighbors(self, X_train, test_row, num_neighbors):\n",
        "#         \"\"\"\n",
        "#         make a prediction with neighbors\n",
        "#         \"\"\"\n",
        "#         n = knn.get_neighbors(X_train, test_row, num_neighbors)\n",
        "#         for row in n:\n",
        "#           vals = row[-1]\n",
        "#         self.pred_neigh = max(set(vals), key=vals.count)\n",
        "\n",
        "\n",
        "#     def predict_classification(self, X_train, X_test, num_neighbors):\n",
        "#         \"\"\"\n",
        "#         K-NN algorithm; determine the class of a test instance\n",
        "#         \"\"\"\n",
        "#         for row in X_test:\n",
        "#           vals = knn.predict_neighbors(X_train, test_row, num_neighbors)\n",
        "#           self.predict_class.append(vals)     \n",
        "\n",
        "    \n",
        "#     # Evaluate K-NN Algorithm\n",
        "#     def accuracy_metrics(self):\n",
        "#         \"\"\"\n",
        "#         calculate accuracy (prediction error) percentage;\n",
        "#         the set of labels predicted for a sample must \n",
        "#         exactly match the corresponding set of labels \n",
        "#         in y_true; return the accuracy score to the screen\n",
        "#         \"\"\"\n",
        "#         for i in range(len(self.class_val_labels)):\n",
        "#           if self.class_val_labels[i] == self.pred_class[i]:\n",
        "#             self.correct +=1\n",
        "#             return (f'Accuracy Score: {self.correct / float(len(self.class_val_labels)) * 100}')\n",
        "\n",
        "\n",
        "#     # def cross_val_metric(self):\n",
        "#     #     \"\"\"\n",
        "#     #     evaluate algorithm (model rules) using cross validation; \n",
        "#     #     validated on the remaining part of the data \n",
        "#     #     (i.e., test set) to compute a performance measure such \n",
        "#     #     as accuracy\n",
        "#     #     \"\"\"\n",
        "#     #     folds = cross_val_split(X_test, k_folds)\n",
        "#     #     self.scores = []\n",
        "\n",
        "#     #     # TODO...refactor in OOP\n",
        "\n",
        "#     #     for f in folds:\n",
        "#     #       train_set = list(folds)\n",
        "#     #       train_set.remove(f)\n",
        "#     #       train_set = sum(train_set, [])\n",
        "\n",
        "#     #       test_set = []\n",
        "#     #       for row in fold:\n",
        "#     #         copy_row = list(row)\n",
        "#     #         test_set.append(copy_row)\n",
        "#     #         # assumes the last value is output\n",
        "#     #         row_copy[-1] = None\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     # X = dataset\n",
        "#     # y = dataframe[\"class\"]\n",
        "\n",
        "#     # Test KNN class initializtion\n",
        "#     knn = KNN(X, y)\n",
        "#     print(X.head())\n",
        "#     print(X.tail())\n",
        "#     X.info()\n",
        "#     print(y.head())\n",
        "\n",
        "#     # test create_unigue_class_id method\n",
        "#     knn.create_unique_class_id(dataframe)\n",
        "#     print(knn.class_val_labels)\n",
        "\n",
        "# # ----- all code above here is running w/o error with both X_train and X_test in df format ----- #\n",
        "\n",
        "#     # test train_test_split method\n",
        "#     knn.train_test_split(X)\n",
        "#     print(f'Train: {knn.X_train}')\n",
        "#     print(f'Test: {knn.X_test}')\n",
        "\n",
        "#     # test min_max method\n",
        "#     knn.min_max(knn.X_train)\n",
        "#     print(knn.minmax)\n",
        "\n",
        "#     # test nortmalize method\n",
        "#     knn.normalize(knn.X_train, knn.minmax)\n",
        "#     print(knn.normalize)\n",
        "\n",
        "# # ----- all code above here is running w/o error as long as X_train is a list ----- #\n",
        "\n",
        "#     # test calculate_ed method\n",
        "#     # print(X_train)\n",
        "#     knn.calculate_ed(knn.X_train[0], knn.X_train[1])\n",
        "#     print(knn.calculate_ed)\n",
        "\n",
        "#     # test get_neighbors method\n",
        "#     knn.get_neighbors(knn.X_train, knn.X_test.iloc[1], 3)\n",
        "#     print(knn.get_neighbors)\n",
        "\n",
        "#     # test predict_neighbors method\n",
        "#     knn.predict_neighbors(knn.X_train, knn.X_test.iloc[1], 3)\n",
        "#     print(knn.predict_neighbors)\n",
        "\n",
        "#     # test predict_classification method\n",
        "#     knn.predict_classification(knn.X_train, knn.X_test, 3)\n",
        "#     print(knn.predict_classification)\n",
        "\n",
        "#     # test accuracy_metrics method\n",
        "#     knn.accuracy_metrics()\n",
        "\n",
        "#     # test cross_val_metric method\n",
        "\n",
        "     "
      ],
      "id": "removable-devil",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIdSPWXikZzt"
      },
      "source": [
        "# K-Nearest Neighbors Classification Algorithim:  SciKit-Learn Model Implementation"
      ],
      "id": "fIdSPWXikZzt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6rPei4BkTMi"
      },
      "source": [
        "# import packages\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n"
      ],
      "id": "v6rPei4BkTMi",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1cF9bRVobJD"
      },
      "source": [
        "n_neighbors = 3\n",
        "random_state = 42\n",
        "\n",
        "# load dataset\n",
        "X = dataset\n",
        "y = dataframe[\"class\"]"
      ],
      "id": "N1cF9bRVobJD",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF2b9kfZpR4T"
      },
      "source": [
        "# split into train/test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.67, random_state=42, stratify = y)"
      ],
      "id": "xF2b9kfZpR4T",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQH7s4zLpwIU"
      },
      "source": [
        "# print(X_train)\n",
        "# print(X_test)\n",
        "# print(y_train)\n",
        "# print(y_test)"
      ],
      "id": "EQH7s4zLpwIU",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90yf-Pqald1C"
      },
      "source": [
        "# reduce dimensions to 2 with neighborhood component analysis\n",
        "nca = make_pipeline(\n",
        "    MinMaxScaler(),\n",
        "    NeighborhoodComponentsAnalysis(n_components=2, \n",
        "                           random_state=random_state)\n",
        "    )\n"
      ],
      "id": "90yf-Pqald1C",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy0okp0NrIpz"
      },
      "source": [
        "# use nearest neighbor classifier to evaluate  the methoda\n",
        "knn =  KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "\n",
        "# fit the method's model\n",
        "nca.fit(X_train, y_train)\n",
        "\n",
        "# fit nearest neighbor classifier on training set\n",
        "knn.fit(nca.transform(X_train), y_train)\n",
        "\n",
        "# predict the class labels for the provided data\n",
        "knn.predict(nca.transform(X_train))\n",
        "\n",
        "# return probability estimates for the test data\n",
        "knn.predict_proba(nca.transform(X_test))\n",
        "\n",
        "# calculate the nearest neighbor accuracy on the test set\n",
        "knn_accuracy_sklearn = knn.score(nca.transform(X_test), y_test)\n",
        "\n",
        "# calculate the nearest neighbor cross validation score on test set\n",
        "scores = cross_val_score(knn, X_train, y_train, cv=5)\n"
      ],
      "id": "cy0okp0NrIpz",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7USebJsdw0s6",
        "outputId": "bcd78f21-e8c9-43a0-803c-65a4efba6212"
      },
      "source": [
        "print(f'Accuracy Score: {knn_accuracy_sklearn}')\n",
        "print(f'Cross-validation Score: {np.mean(scores)}')\n",
        "# 0.967 is a good score for this dataset"
      ],
      "id": "7USebJsdw0s6",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.9702970297029703\n",
            "Cross-validation Score: 0.9800000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 980
        },
        "id": "sJMZKmZiRtQo",
        "outputId": "14f58a1c-10cd-42c8-ffe8-fad4826fa6ce"
      },
      "source": [
        "class KNearestNeighbors(object):\n",
        "  def __init__(self, k):\n",
        "    self.k = k\n",
        "  \n",
        "  def train_test_split(dataset, test_size=0.33):\n",
        "    n_test = int(len(dataset) * test_size)\n",
        "    test_set = dataset(n_test)\n",
        "    train_set = []\n",
        "    for idx in dataset.index:\n",
        "      if idx in test_set.index:\n",
        "        continue\n",
        "        train_set.append(dataset.iloc[idx])\n",
        "\n",
        "    train_set = pd.DataFram(train_set).astype(float).values.tolist()\n",
        "    test_set = test_set.astype(float).values.tolist()\n",
        "\n",
        "    return train_set, test_set\n",
        "\n",
        "\n",
        "  def euclidean_dist(v1, v2):\n",
        "    v1, v2 = nparray(v1), nparray(v2)\n",
        "    distance = 0\n",
        "    for i in range(len(v1) -1):\n",
        "      distance += (v1[i] - v2[i]) **2\n",
        "\n",
        "    return np.sqrt(distance)\n",
        "  \n",
        "\n",
        "  def predict(self, train_set, test_instance):\n",
        "    distances = []\n",
        "    for i in range(len(train_set)):\n",
        "      dist = self.euclidean_dist(train_set[i][:-1], test_instance)\n",
        "      distances.append((train_set[i], dist))\n",
        "      distances.sort(key=lambda x: x[1])\n",
        "\n",
        "    neighbors = []\n",
        "    for i in range(self.k):\n",
        "      neighbors.append(distances[i][0])\n",
        "\n",
        "    classes = {}\n",
        "    for i in range(len(neighbors)):\n",
        "      response = neighbors[i][-1]\n",
        "      if response in classes:\n",
        "        classes[response] +=1\n",
        "      else:\n",
        "        classes[response] =1\n",
        "\n",
        "      sorted_classes = sorted(classes.items(), key=lambda x: x[1], reverse=True)\n",
        "      return sorted_classes[0][0]\n",
        "\n",
        "\n",
        "    def evaluate(y_true, y_pred):\n",
        "      correct = 0\n",
        "      for actual, pred in zip(y_true, y_pred):\n",
        "        if actual == pred:\n",
        "          correct +=1\n",
        "          return correct / len(y_true)\n",
        "\n",
        "# driver code\n",
        "train_set, test_set = train_test_split(dataset)\n",
        "print(len(train_set), len(test_set))\n",
        "\n",
        "knn = KNearestNeighbors(k=3)\n",
        "preds = []\n",
        "\n",
        "for row in test_set:\n",
        "  preds_only = row[:-1]\n",
        "  prediction = knn.predict(train_set, preds_only)\n",
        "  preds.append(prediction)\n",
        "\n",
        "actual = np.array(test_set)[:, -1]\n",
        "knn.evaluate(actual, preds)\n",
        "\n",
        "print(knn.evaluate)\n"
      ],
      "id": "sJMZKmZiRtQo",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "112 38\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-9fc238284801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0mpreds_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-9fc238284801>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, train_set, test_instance)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuclidean_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m       \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "YuctGeMPYGA8",
        "outputId": "0d90aaa8-c318-42de-870b-5bc717dab78a"
      },
      "source": [
        "print((train_set[0][:-1]))"
      ],
      "id": "YuctGeMPYGA8",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d8581c28045f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    }
  ]
}